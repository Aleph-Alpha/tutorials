{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Customise prompts for structured responses\n",
    "\n",
    "One of the most effective ways to improve the quality of your RAG application is to customise the prompt that is sent to the LLM. By modifying the prompt, you can control the format, style, and content of the generated responses.\n",
    "\n",
    "We will explore how to modify the prompt to generate more structured responses. For example, you might want responses that:\n",
    "\n",
    "- Include specific sections like \"Summary\" and \"Details\"\n",
    "- Clearly indicate which parts are from the documents and which are from the LLM's knowledge\n",
    "- Follow a consistent formatting style\n",
    "\n",
    "The following shows how you could modify the prompt in the Q&A Skill template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a modified prompt for structured responses\n",
    "content = f\"\"\"\n",
    "    Using the provided context documents below, answer the following question.\n",
    "    Format your response with the following sections: \n",
    "        1. SUMMARY: A brief 1-2 sentence answer to the question \n",
    "        2. DETAILS: A comprehensive explanation with specific information from the context \n",
    "        3. SOURCES: References to the specific parts of the context you used, if applicable If the information is not available in the context documents, clearly state this and provide a general response based on your knowledge, marked as [GENERAL KNOWLEDGE].\n",
    "\n",
    "    Input: {context}\n",
    "\n",
    "    Question: {input.question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement this change, you replace the `content` variable in your Skill function with the modified prompt above. This instructs the LLM to structure its response with specific sections, making the information more organised and easier to read.\n",
    "\n",
    "For even more control, you can use a system message to set persistent instructions for the LLM.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> After changing the skill code, it is necessary to re-deploy the skill to be able to see the changes in Assistant (even when using the Dev Mode)</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different prompt variations to find the structure that works best for your specific use case. Keep in mind that the prompt should be clear and specific about what you want the LLM to do, while leaving enough flexibility for it to generate helpful responses.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
