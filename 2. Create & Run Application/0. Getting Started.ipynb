{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started - Create & Run Application\n",
    "\n",
    "Welcome to the application creation phase of the PhariaAI tutorial! This guide will help you set up your environment to build and run custom applications with PhariaAI.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "This tutorial will show you how to:\n",
    "- Activate your existing virtual environment from the previous tutorial\n",
    "- Install additional dependencies needed for application development\n",
    "- Run terminal commands to build and deploy your PhariaAI applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# The Core Concepts\n\n<details>\n<summary><strong>ðŸ“š Click to expand Core Concepts section</strong></summary>\n\n<br>\n\n> **Note:** This section provides a quick mental model of how PhariaKernel components work together. Detailed implementation steps follow in the next notebooks.\n\n## Quick Overview\n\nPhariaKernel lets you deploy AI components as serverless functions. Here's the workflow:\n\n1. **Write** a Skill (Python function with AI logic)\n2. **Build** it to WebAssembly \n3. **Publish** to a registry\n4. **Configure** which Skills are available\n5. **Invoke** via REST API\n\n<div align=\"center\">\n  <img src=\"./images/skill_flow.png\" width=\"600\" alt=\"PhariaKernel Deployment Workflow\">\n  <p><em>Complete deployment workflow from development to production</em></p>\n</div>\n\n---\n\n## Concept 1: The PhariaKernel Instance\n\n**What:** A serverless runtime specifically designed for AI workloads - think AWS Lambda, but optimized for AI.\n\n**Why it matters:** Handles all infrastructure complexity (scaling, queuing, load balancing) so you focus only on AI logic.\n\n**To connect:** You need two environment variables from your PhariaKernel operator:\n```bash\nPHARIA_KERNEL_ADDRESS=<your-instance-url>\nPHARIA_AI_TOKEN=<your-auth-token>\n```\n\n---\n\n## Concept 2: Skills\n\n**What:** Python functions that encapsulate AI logic with defined input/output schemas using Pydantic models.\n\n**Why it matters:** Skills are stateless, strongly-typed, and testable - perfect for production AI systems.\n\n<div align=\"center\">\n  <img src=\"./images/skill_structure.png\" width=\"400\" alt=\"Skill Structure\">\n  <p><em>Anatomy of a Skill: Input Schema â†’ Business Logic â†’ Output Schema</em></p>\n</div>\n\n**Example:**\n```python\nfrom pharia_skill import ChatParams, Csi, Message, skill\nfrom pydantic import BaseModel\n\nclass Input(BaseModel):\n    topic: str\n\nclass Output(BaseModel):\n    haiku: str\n\n@skill\ndef create_haiku(csi: Csi, input: Input) -> Output:\n    response = csi.chat(\n        \"llama-3.1-8b-instruct\",\n        [Message.user(f\"Write a haiku about {input.topic}\")],\n        ChatParams(max_tokens=64)\n    )\n    return Output(haiku=response.message.content)\n```\n\n---\n\n## Concept 3: Building Skills\n\n**What:** Compile your Python Skill to WebAssembly for secure, portable execution.\n\n**Why it matters:** WASM provides isolation, consistent performance, and language independence.\n\n<div align=\"center\">\n  <img src=\"./images/skill_build.png\" width=\"500\" alt=\"Build Process\">\n  <p><em>Build process transforms Python code into portable WebAssembly</em></p>\n</div>\n\n**Command:**\n```bash\nuv run pharia-skill build my_skill\n```\nThis creates `my_skill.wasm` ready for deployment.\n\n---\n\n## Concept 4: Skill Registry\n\n**What:** A container registry (like Docker Hub) but for WASM components.\n\n**Why it matters:** Central storage for versioned Skills that PhariaKernel can load on-demand.\n\n<div align=\"center\">\n  <img src=\"./images/skill_registry.png\" width=\"450\" alt=\"Skill Registry\">\n  <p><em>OCI-compliant registries store and version your Skills</em></p>\n</div>\n\n**Setup:** Configure registry credentials (get from your DevOps team):\n```bash\nexport SKILL_REGISTRY=registry.example.com      # Registry URL\nexport SKILL_REPOSITORY=team/skills             # Your namespace\nexport SKILL_REGISTRY_USER=<username>           # Your username  \nexport SKILL_REGISTRY_TOKEN=<token>             # Access token\n```\n\n**Publish:**\n```bash\nuv run pharia-skill publish my_skill.wasm --name my_skill\n```\n\n---\n\n## Concept 5: Namespace Configuration\n\n**What:** A TOML file that declares which Skills should be available in your namespace.\n\n**Why it matters:** Controls what Skills are loaded and accessible via API.\n\n<div align=\"center\">\n  <img src=\"./images/skill_namespace.png\" width=\"500\" alt=\"Namespace Configuration\">\n  <p><em>GitOps workflow: Configuration changes trigger automatic Skill deployment</em></p>\n</div>\n\n**Example `namespace.toml`:**\n```toml\nskills = [\n    { name = \"my_skill\", tag = \"latest\" },\n    { name = \"another_skill\", tag = \"v1.0.0\" }\n]\n```\n\n**Update process:** \n1. Edit namespace.toml in your Git repo\n2. Create pull request\n3. Merge â†’ PhariaKernel auto-loads new Skills\n\n---\n\n## Concept 6: Invoking Skills\n\n**What:** Call your deployed Skills via REST API.\n\n**Example:**\n```bash\ncurl 'https://pharia-kernel.domain/v1/skills/{namespace}/{skill_name}/run' \\\n  --header \"Authorization: Bearer $PHARIA_AI_TOKEN\" \\\n  --header 'Content-Type: application/json' \\\n  --data '{\"topic\": \"mountains\"}'\n```\n\n**Response:**\n```json\n{\n  \"haiku\": \"Peaks touch the sky high\\nSnow-capped giants stand in silence\\nClouds dance at their feet\"\n}\n```\n\n---\n\n## ðŸŽ¯ Key Takeaway\n\nPhariaKernel transforms your Python AI functions into production-ready, scalable services with just a few commands. The complexity is hidden - you write Python, PhariaKernel handles the rest.\n\n> **Need Details?** Contact your PhariaKernel operator for environment-specific setup. They'll provide connection details, registry access, and namespace configuration.\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "\n",
    "### Accessing Your Virtual Environment\n",
    "\n",
    "If you completed the previous [**\"0. Getting Started - Document Search Setup\"**](../1.%20Enable%20searching%20documents/0.%20Getting%20Started.ipynb) tutorial, you already have a virtual environment set up. Simply activate it:\n",
    "\n",
    "**On macOS/Linux:**\n",
    "```python\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "**On Windows:**\n",
    "```PowerShell\n",
    ".venv\\Scripts\\activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Software Installation\n",
    "\n",
    "You'll need additional tools for application development and containerization.\n",
    "\n",
    "### 1. Installing Node.js and npx\n",
    "\n",
    "**macOS Installation:**\n",
    "\n",
    "1. **Install Node.js using Homebrew** (if not already installed):\n",
    "   ```bash\n",
    "   brew install node\n",
    "   ```\n",
    "   This automatically includes `npx`.\n",
    "\n",
    "2. **Verify installation:**\n",
    "   ```bash\n",
    "   node --version\n",
    "   npx --version\n",
    "   ```\n",
    "\n",
    "**Windows Installation:**\n",
    "\n",
    "1. **Install Node.js:** Download from https://nodejs.org/en/download (Versions 20.0 or higher)\n",
    "   This automatically includes `npx`.\n",
    "\n",
    "2. **Verify installation:**\n",
    "   ```bash\n",
    "   node --version\n",
    "   npx --version\n",
    "   ```\n",
    "\n",
    "### 2. Docker/Rancher Installation\n",
    "\n",
    "You will need container technology to build images in the later parts of this tutorial:\n",
    "\n",
    "**macOS:**\n",
    "- **Docker:** https://docs.docker.com/desktop/setup/install/mac-install/\n",
    "- **Rancher Desktop** (alternative): https://docs.rancherdesktop.io/getting-started/installation/\n",
    "\n",
    "**Windows:**\n",
    "- **Docker:** https://docs.docker.com/desktop/setup/install/windows-install/\n",
    "- **Rancher Desktop** (alternative): https://docs.rancherdesktop.io/getting-started/installation/\n",
    "\n",
    "\n",
    "### 3. Additional Dependencies\n",
    "\n",
    "If you haven't installed `pharia-skill` from the previous tutorial, add it now:\n",
    "\n",
    "```bash\n",
    "uv pip install pharia-skill\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: Terminal-Based Workflow\n",
    "\n",
    "### Multiple Terminal Sessions Required\n",
    "\n",
    "Unlike the previous tutorial that used Jupyter notebooks, **this section requires working directly in terminal windows**. You will often need to:\n",
    "\n",
    "1. **Keep multiple terminal sessions open simultaneously**\n",
    "2. **Run commands in separate terminal windows**\n",
    "3. **Monitor different processes in parallel**\n",
    "\n",
    "### Example Workflow\n",
    "\n",
    "You might have:\n",
    "- **Terminal 1:** Running the application server\n",
    "- **Terminal 2:** Building Docker images  \n",
    "- **Terminal 3:** Monitoring logs or running additional commands"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}