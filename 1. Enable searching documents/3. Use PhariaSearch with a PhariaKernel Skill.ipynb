{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PhariaSearch with PhariaKernel Skills\n",
    "\n",
    "### Load the Enviroment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "NAMESPACE = getenv(\"PHARIA_DATA_NAMESPACE\")\n",
    "COLLECTION = getenv(\"PHARIA_DATA_COLLECTION\")\n",
    "INDEX = getenv(\"INDEX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Skill\n",
    "\n",
    "PhariaSearch is natively integrated within PhariaKernel to reduce the effort necessary to develop a RAG based system.\n",
    "\n",
    "The PhariaSkill SDK is available on PyPI (https://pypi.org/project/pharia-skill/) and can be installed with `pip install pharia-skill`. Let's start by importing the necessary dependencies.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "PhariaKernel supports only semantic search and not filter indexes or hybrid indexes. This will be supported in the near future.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_skill import ChatParams, Csi, IndexPath, Message, skill\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the basic Input and Output structure to make our RAG skill works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(BaseModel):\n",
    "    question: str\n",
    "    namespace: str = NAMESPACE\n",
    "    collection: str = COLLECTION\n",
    "    index: str = INDEX\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    answer: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define our AI logic within the skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@skill\n",
    "def rag_skill(csi: Csi, input: Input) -> Output:\n",
    "    index = IndexPath(\n",
    "        namespace=input.namespace,\n",
    "        collection=input.collection,\n",
    "        index=input.index,\n",
    "    )\n",
    "\n",
    "    if not (documents := csi.search(index, input.question, 3, 0.5)):\n",
    "        return Output(answer=None)\n",
    "\n",
    "    context = \"\\n\".join([d.content for d in documents])\n",
    "    content = f\"\"\"Using the provided context documents below, answer the following question accurately and comprehensively. If the information is directly available in the context documents, cite it clearly. If not, use your knowledge to fill in the gaps while ensuring that the response is consistent with the given information. Do not fabricate facts or make assumptions beyond what the context or your knowledge base provides. Ensure that the response is structured, concise, and tailored to the specific question being asked.\n",
    "\n",
    "Input: {context}\n",
    "\n",
    "Question: {input.question}\n",
    "\"\"\"\n",
    "    message = Message.user(content)\n",
    "    params = ChatParams(max_tokens=512)\n",
    "    response = csi.chat(\"llama-3.1-8b-instruct\", [message], params)\n",
    "    return Output(answer=response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your skill with DevCSI\n",
    "\n",
    "Now that the Skill is defined, it is possible to test it locally using the DevCSI provided by Kernel, that requires two extra environment variables:\n",
    "\n",
    "```bash\n",
    "PHARIA_AI_TOKEN=\n",
    "PHARIA_KERNEL_ADDRESS=\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_skill.testing import DevCsi\n",
    "\n",
    "csi = DevCsi()\n",
    "result = rag_skill(csi, Input(question=\"What is the influence of Robert Moses?\"))\n",
    "\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move the skill to production\n",
    "\n",
    "Once the Skill is ready, it is possible to deploy it to production by following the steps in the <a href=\"https://docs.aleph-alpha.com/products/pharia-ai/pharia-studio/pharia-kernel/quick_start\">Quick Start with Kernel skills</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
