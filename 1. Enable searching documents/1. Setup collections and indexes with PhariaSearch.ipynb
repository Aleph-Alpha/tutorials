{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup collections and indexes with PhariaSearch\n",
    "\n",
    "While large language models come equipped with extensive built-in knowledge, answering questions given a known text may not be sufficient for your use case. At some point, you will probably want to search through, or answer questions about, your own knowledge base.\n",
    "\n",
    "You can leverage Aleph Alpha's PhariaSearch (previously known as DocumentIndex) ‚Äì a robust semantic search tool ‚Äì to pinpoint sections in documents that align closely with your query.\n",
    "\n",
    "In this tutorial, we will go through the creation of Collections and Index configurations, and the upload of text directly to PhariaSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Validation\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL: Validate your environment before proceeding**\n",
    "\n",
    "This step ensures your `.env` file is properly configured with valid API endpoints, authentication tokens, and unique resource names.\n",
    "\n",
    "**DO NOT SKIP!** If validation fails:\n",
    "- Check your `.env` file for missing values\n",
    "- Contact your infrastructure administrator if errors persist\n",
    "\n",
    "Only proceed after ALL checks pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating environment configuration...\n",
      "\n",
      "1Ô∏è‚É£  Checking required environment variables:\n",
      "   ‚úÖ PHARIA_API_BASE_URL: https://api.customer.pharia.com\n",
      "   ‚úÖ PHARIA_AI_TOKEN: eyJhbGci...\n",
      "   ‚úÖ PHARIA_DATA_NAMESPACE: Studio\n",
      "   ‚úÖ PHARIA_DATA_COLLECTION: pharia-tutorial-rag-vsp-1\n",
      "   ‚úÖ INDEX: rag-tutorial-index-1\n",
      "   ‚úÖ HYBRID_INDEX: rag-tutorial-hybrid-index-vsp-1\n",
      "   ‚úÖ FILTER_INDEX: rag-tutorial-filter-index-vsp-1\n",
      "   ‚úÖ EMBEDDING_MODEL_NAME: luminous-base\n",
      "\n",
      "2Ô∏è‚É£  Validating URL format:\n",
      "   ‚úÖ PHARIA_API_BASE_URL: Valid format\n",
      "\n",
      "3Ô∏è‚É£  Testing PhariaAI API access:\n",
      "   ‚úÖ API connection successful\n",
      "\n",
      "==================================================\n",
      "‚úÖ All validation checks passed! Your environment is properly configured.\n",
      "\n",
      "You can now proceed with the tutorial.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validation_utils import validate_environment\n",
    "\n",
    "# Run environment validation\n",
    "validate_environment()\n",
    "\n",
    "# If validation fails, DO NOT proceed with the rest of the tutorial\n",
    "# Fix the issues identified above first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "  Now we'll load all the configuration parameters from your `.env` file. These include API endpoints, authentication tokens, and the names of resources\n",
    "  we'll create in PhariaSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Loading environment variables...\")\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Please make sure to include the /v1 in the api base url\n",
    "PHARIA_API_BASE_URL = getenv(\"PHARIA_API_BASE_URL\")\n",
    "PHARIA_SEARCH_API_URL = f\"{PHARIA_API_BASE_URL}/v1/studio/search\"\n",
    "TOKEN = getenv(\"PHARIA_AI_TOKEN\")\n",
    "\n",
    "NAMESPACE = getenv(\"PHARIA_DATA_NAMESPACE\")\n",
    "COLLECTION = getenv(\"PHARIA_DATA_COLLECTION\")\n",
    "INDEX = getenv(\"INDEX\")\n",
    "HYBRID_INDEX = getenv(\"HYBRID_INDEX\")\n",
    "FILTER_INDEX = getenv(\"FILTER_INDEX\")\n",
    "\n",
    "EMBEDDING_MODEL_NAME = getenv(\"EMBEDDING_MODEL_NAME\")\n",
    "print(f\"Environment variables loaded successfully!\")\n",
    "print(f\"  - API Base URL: {PHARIA_API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup a Search Client with Pharia Data SDK\n",
    "\n",
    "To search through PhariaSearch, you'll first need to setup the Search Client using the environment variables we specified at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors import DocumentIndexClient\n",
    "\n",
    "search_client = DocumentIndexClient(\n",
    "    token=TOKEN,\n",
    "    base_url=PHARIA_SEARCH_API_URL,\n",
    ")\n",
    "try:\n",
    "    print(f\"Search client created successfully. \\n Remote server available at {search_client._base_url}\")\n",
    "except AttributeError:\n",
    "    print(\"Search client created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a collection\n",
    "The collection is the place where our searchable content will be stored. The following code will user the Pharia Data SDK to create a new collection with the specified details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors.document_index.document_index import CollectionPath\n",
    "\n",
    "collection_path = CollectionPath(namespace=NAMESPACE, collection=COLLECTION)\n",
    "\n",
    "search_client.create_collection(collection_path)\n",
    "\n",
    "print(f\"Collection created successfully. \\n Collection path: {collection_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a semantic index configuration\n",
    "\n",
    "Now, let's create an index and assign it to this collection. You can do this before or after populating the collection with documents; PhariaSearch automatically updates semantic indexes in the background.\n",
    "In this tutorial we use `pharia-1-embedding-256-control` embedding model. If this model is not available in the environment, please, replace the name with the one that is available (e.g. `luminous-base`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors.document_index.document_index import (\n",
    "    IndexConfiguration,\n",
    "    IndexPath,\n",
    "    SemanticEmbed,\n",
    ")\n",
    "\n",
    "index_path = IndexPath(namespace=NAMESPACE, index=INDEX)\n",
    "\n",
    "# customise the parameters of the index here\n",
    "index_configuration = IndexConfiguration(\n",
    "    chunk_size=64,\n",
    "    chunk_overlap=0,\n",
    "    embedding=SemanticEmbed(model_name=EMBEDDING_MODEL_NAME, representation=\"asymmetric\"),\n",
    ")\n",
    "\n",
    "search_client.create_index(index_path, index_configuration)\n",
    "\n",
    "print(f\"Index created successfully. \\n Index path: {index_path}\")\n",
    "\n",
    "# assign the index to the collection\n",
    "search_client.assign_index_to_collection(collection_path, INDEX)\n",
    "\n",
    "print(f\"Index assigned to collection successfully. \\n Collection path: {collection_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload some text to the collection\n",
    "\n",
    "Now that we have our collection set up, we need to populate it with content that can be searched. Let's create three text objects that will serve as our sample knowledge base. These documents will demonstrate how PhariaSearch can identify relevant information across different types of content.\n",
    "\n",
    "We'll add biographical information about notable figures to showcase the semantic search capabilities. The document content is defined in `sample_documents.py` file, outside of the notebook and imported below.\n",
    "\n",
    "We'll upload each document to our collection. The SDK will automatically handle the document storage and prepare them for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors.document_index.document_index import (\n",
    "    DocumentContents,\n",
    "    DocumentPath,\n",
    ")\n",
    "\n",
    "from sample_documents import documents\n",
    "\n",
    "for doc in documents:\n",
    "    document_path = DocumentPath(\n",
    "        collection_path=collection_path, document_name=doc[\"name\"]\n",
    "    )\n",
    "    search_client.add_document(\n",
    "        document_path, contents=DocumentContents.from_text(doc[\"content\"])\n",
    "    )\n",
    "    print(f\"Document `{doc['name']}` uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Verify Documents in Collection\n",
    "\n",
    "  Let's verify that our documents have been successfully uploaded to the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client.documents(collection_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the text is indexed, we can also have a look at its chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors import ResourceNotFound\n",
    "\n",
    "try:\n",
    "    chunks = search_client.chunks(\n",
    "        DocumentPath(collection_path=collection_path, document_name=documents[0][\"name\"]),\n",
    "        index_name=INDEX,\n",
    "    )\n",
    "    print(chunks)\n",
    "except ResourceNotFound:\n",
    "    pass  # This is expected if the document is still embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup search indexes\n",
    "\n",
    "### 5.1. Perform semantic search\n",
    "\n",
    "Now that we have uploaded our text, we can search through it using the semantic similarities between a given query and each chunk.\n",
    "\n",
    "To do so, let's use the `DocumentIndexRetriever`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_data_sdk.connectors.retrievers import DocumentIndexRetriever\n",
    "\n",
    "document_index_retriever = DocumentIndexRetriever(\n",
    "    document_index=search_client,\n",
    "    index_name=INDEX,\n",
    "    namespace=NAMESPACE,\n",
    "    collection=COLLECTION,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "document_index_retriever.get_relevant_documents_with_scores(\n",
    "    query=\"The influence of Robert Moses\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hybrid Search\n",
    "\n",
    "PhariaSearch supports hybrid search, which combines results of semantic search and keyword search.\n",
    "In order to use hybrid search, we need to create a hybrid index and assign it to the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = IndexPath(namespace=NAMESPACE, index=HYBRID_INDEX)\n",
    "\n",
    "# customise the parameters of the index here\n",
    "index_configuration = IndexConfiguration(\n",
    "    chunk_size=64,\n",
    "    chunk_overlap=0,\n",
    "    hybrid_index=\"bm25\",\n",
    "    embedding=SemanticEmbed(model_name=EMBEDDING_MODEL_NAME, representation=\"asymmetric\"),\n",
    ")\n",
    "\n",
    "# create the namespace-wide index resource\n",
    "search_client.create_index(index_path, index_configuration)\n",
    "\n",
    "# assign the index to the collection\n",
    "search_client.assign_index_to_collection(collection_path, HYBRID_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client.list_indexes(NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now search on the hybrid index, we will not only get chunks with a semantic similarity but also chunks that match the keywords in the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='jane_jacobs'), score=0.5, document_chunk=DocumentChunk(text='Jane Jacobs OC OOnt (n√©e Butzner; 4 May 1916 ‚Äì 25 April 2006) was an American-Canadian journalist, author, theorist, and activist who influenced urban studies, sociology, and economics.', start=0, end=184, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.33333334, document_chunk=DocumentChunk(text=\"www.nycroads.com/roads/taconic/ |title=Taconic State Parkway |website=NYCRoads.com |access-date=May 25, 2006}}</ref> Moses helped build Long Island's [[Meadowbrook State Parkway]].\", start=10999, end=11178, metadata=None))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index_retriever = DocumentIndexRetriever(\n",
    "    document_index=search_client,\n",
    "    index_name=HYBRID_INDEX,\n",
    "    namespace=NAMESPACE,\n",
    "    collection=COLLECTION,\n",
    "    k=5,\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "document_index_retriever.get_relevant_documents_with_scores(query=\"25 April\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  Search with Metadata filtering\n",
    "\n",
    "PhariaSearch also supports filter-indexes, which gives us the ability to provide specific filters in case we want to filter our search based on each document's metadata.\n",
    "\n",
    "To do so, let's first upload another version of our documents but this time with some metadata e.g. the \"title\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document `robert_moses` with metadata `'title': robert_moses` uploaded successfully.\n",
      "Document `jane_jacobs` with metadata `'title': jane_jacobs` uploaded successfully.\n",
      "Document `nelson_rockefeller` with metadata `'title': nelson_rockefeller` uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    document_path = DocumentPath(\n",
    "        collection_path=collection_path, document_name=doc[\"name\"]\n",
    "    )\n",
    "    search_client.add_document(\n",
    "        document_path,\n",
    "        contents=DocumentContents(\n",
    "            contents=[doc[\"content\"]], metadata={\"title\": doc[\"name\"]}\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Document `{doc['name']}` with metadata `'title': {doc['name']}` uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of the Filter Index\n",
    "To be able to use metadata filtering, we need to first check the following:\n",
    "1. Check if we already have a search index assigned. If not, we need to assign one because filter-indexes can be defined at the namespace level but can only be assigned to already existing search indexes \n",
    "2. Define a new filter-index configuration for our specific collection metadata.\n",
    "3. Assign the filter-index that we created to a search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rag-tutorial-hybrid-index-vsp-1',\n",
       " 'rag-tutorial-index-vps-1',\n",
       " 'rag-tutorial-index-1']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "# list all the assigned search indexes for our collection\n",
    "search_client.list_assigned_index_names(collection_path=collection_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter rag-tutorial-filter-index-vsp-1 has been created.\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# define a new filter-index\n",
    "search_client.create_filter_index_in_namespace(\n",
    "    namespace=collection_path.namespace,\n",
    "    filter_index_name=FILTER_INDEX,  # this is how our filter-index is identified in our namespace\n",
    "    field_name=\"title\",  # this is the name of the field to which we want to apply our filter\n",
    "    field_type=\"string\",  # type of the field we want to apply our filter to. Must be one of \"string\", \"integer\", \"float\", \"boolean\" or \"datetime\"\n",
    ")\n",
    "\n",
    "# let's check if our index is present now\n",
    "filter_present = FILTER_INDEX in search_client.list_filter_indexes_in_namespace(\n",
    "    namespace=collection_path.namespace\n",
    ")\n",
    "if (filter_present):\n",
    "    print(f\"Filter {FILTER_INDEX} has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of filters assigned to namespace='Studio' collection='pharia-tutorial-rag-vsp-1':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rag-tutorial-filter-index-vsp-1']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "# assign our new filter-index to our collection\n",
    "search_client.assign_filter_index_to_search_index(\n",
    "    collection_path=collection_path,\n",
    "    index_name=INDEX,  # we assign it to intelligence-layer-sdk-demo-index\n",
    "    filter_index_name=FILTER_INDEX,\n",
    ")\n",
    "\n",
    "# check if our filter-index is assigned to our collection\n",
    "print(f\"List of filters assigned to {collection_path}:\")\n",
    "search_client.list_assigned_filter_index_names(\n",
    "    collection_path=collection_path, index_name=INDEX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, as we have the filter-index enabled, we need to initialize a new `DocumentIndexRetriever` with the search index for which we added the filter-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_index_retriever instance created for index=rag-tutorial-index-1, namespace=Studio, collection=pharia-tutorial-rag-vsp-1\n"
     ]
    }
   ],
   "source": [
    "document_index_retriever = DocumentIndexRetriever(\n",
    "    document_index=search_client,\n",
    "    index_name=INDEX,\n",
    "    namespace=NAMESPACE,\n",
    "    collection=COLLECTION,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(f\"document_index_retriever instance created for index={INDEX}, namespace={NAMESPACE}, collection={COLLECTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining and Using a Filter\n",
    "Before we perform the filtered search we have to define a filter.\n",
    "Filters are composed of the following elements:\n",
    "- `filter_type` which can be one of \"with\", \"without\" or \"with_one_of\"\n",
    "- `filter_fields`, which defines the actual filtering criteria over a certain value for our chosen field\n",
    "\n",
    "If we want a filter that accepts only documents with the value of the \"title\" field equal to the \"name\" field of `document_1`, we define the filter as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter instance created: \n",
      " (filter_type='with' fields=[FilterField(field_name='title', field_value='robert_moses', criteria=<FilterOps.EQUAL_TO: 'equal_to'>)])\n"
     ]
    }
   ],
   "source": [
    "from pharia_data_sdk.connectors import FilterField, FilterOps, Filters\n",
    "\n",
    "filters = Filters(\n",
    "    filter_type=\"with\",  # we want to only return documents matching our filter\n",
    "    fields=[\n",
    "        FilterField(\n",
    "            field_name=\"title\",  # this is the key we used in our metadata dict\n",
    "            field_value=documents[0][\n",
    "                \"name\"\n",
    "            ],  # this is what we used as a value in the metadata dict\n",
    "            criteria=FilterOps.EQUAL_TO,  # we want to match exactly\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(f\"Filter instance created: \\n ({filters})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.8402531, document_chunk=DocumentChunk(text=\"Robert Moses''' (December 18, 1888 ‚Äì July 29, 1981) was an American [[urban planner]] and public official who worked in the [[New York metropolitan area]] during the early to mid 20th century.\", start=0, end=191, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.6727346, document_chunk=DocumentChunk(text='1914, Moses became attracted to New York City reform politics.<ref>{{Cite web|url=http://c250.columbia.edu/c250_celebrates/remarkable_columbians/robert_moses.html|title = Robert Moses}}</ref> A committed [[', start=5403, end=5608, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.66066474, document_chunk=DocumentChunk(text='of-robert-moses/16018/|title=The legacy of Robert Moses|last=Sarachan|first=Sydney|date=January 17, 2013|website=Need to Know {{!}}', start=876, end=1006, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.6436805, document_chunk=DocumentChunk(text='html | title=Robert Moses, Master Builder, is Dead at 92| newspaper=The New York Times |archive-url=https://web.archive.org/web/20160305003155/https://www.nytimes.com/learning/general/onthisday/bday/1218', start=3524, end=3726, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='robert_moses'), score=0.61724025, document_chunk=DocumentChunk(text='As head of the [[MTA Bridges and Tunnels|Triborough Bridge Authority]], Moses had near-complete control over bridges and tunnels in New York City as well as the tolls collected from them, and built, among others, the [[Robert F.', start=2202, end=2429, metadata=None))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the filters with our query to restrict the search to documents with the title \"robert_moses\"\n",
    "document_index_retriever.get_relevant_documents_with_scores(\n",
    "    query=\"Robert Moses\", filters=[filters]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We only get document with the \"robert_moses\" as the exact title in the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclusion of Documents\n",
    "We can also modify our filter such that we only get documents that do *not* match the specified filter fields. This is as simply as replacing the \"with\" filter_type with a \"without\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter instance created: \n",
      " (filter_type='with' fields=[FilterField(field_name='title', field_value='robert_moses', criteria=<FilterOps.EQUAL_TO: 'equal_to'>)])\n"
     ]
    }
   ],
   "source": [
    "# let's now try to exclude the document with the title \"robert_moses\"\n",
    "filters_without = Filters(\n",
    "    filter_type=\"without\",  # we change this to \"without\" to exclude the document\n",
    "    fields=[\n",
    "        FilterField(\n",
    "            field_name=\"title\",  # this is the key we used in our metadata dict\n",
    "            field_value=documents[0][\n",
    "                \"name\"\n",
    "            ],  # this is what we used as a value in the metadata dict\n",
    "            criteria=FilterOps.EQUAL_TO,  # we want to match exactly\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(f\"Filter instance created: \\n ({filters})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='jane_jacobs'), score=0.39886028, document_chunk=DocumentChunk(text='Jacobs organized grassroots efforts to protect neighborhoods from urban renewal and slum clearance ‚Äì in particular plans by Robert Moses to overhaul her own Greenwich Village neighborhood.', start=346, end=533, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='nelson_rockefeller'), score=0.3330956, document_chunk=DocumentChunk(text=\"As Governor of New York from 1959 to 1973, Rockefeller's achievements included the expansion of the State University of New York (SUNY), efforts to protect the environment, the construction of the Empire State Plaza in Albany, increased facilities and personnel for medical care, and the creation of the New York State Council on the Arts\", start=1241, end=1578, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='nelson_rockefeller'), score=0.3214534, document_chunk=DocumentChunk(text='Rockefeller, he was a noted art collector and served as administrator of Rockefeller Center in Manhattan, New York City.', start=787, end=906, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='nelson_rockefeller'), score=0.2976044, document_chunk=DocumentChunk(text='A member of the Republican Party and the wealthy Rockefeller family, he previously served as the 49th governor of New York from 1959 to 1973. Rockefeller also served as assistant secretary of State for American Republic Affairs for Presidents Franklin D. Roosevelt and Harry S.', start=259, end=535, metadata=None)),\n",
       " SearchResult(id=DocumentPath(collection_path=CollectionPath(namespace='Studio', collection='pharia-tutorial-rag-vsp-1'), document_name='jane_jacobs'), score=0.285734, document_chunk=DocumentChunk(text='She was instrumental in the eventual cancellation of the Lower Manhattan Expressway,[3] which would have passed directly through the area of Manhattan that would later become known as SoHo, as well as part of Little Italy and Chinatown.[', start=535, end=771, metadata=None))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the filters with our query to exclude the document with the title \"robert_moses\"\n",
    "document_index_retriever.get_relevant_documents_with_scores(\n",
    "    query=\"Robert Moses\", filters=[filters_without]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how we only get results where the `document_name` is not \"robert_moses\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n",
    "\n",
    "We have now a collection with some documents uploaded and with semantic indexing, hybrid indexing, and the possibility to use metadata for filtering results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
