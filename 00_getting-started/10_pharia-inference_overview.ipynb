{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharia Inference Overview\n",
    "\n",
    "Welcome to Pharia Inference - your gateway to powerful language models within the PhariaAI ecosystem. Whether you're building intelligent applications, enhancing customer experiences, or exploring the frontiers of AI, Pharia Inference provides the API you need to bring advanced language understanding to life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pharia Inference?\n",
    "\n",
    "Pharia Inference is the API service that gives you access to state-of-the-art language models. Through simple API calls, you can:\n",
    "\n",
    "- **Generate human-like text** - Create content, answer questions, and engage in natural conversations\n",
    "- **Extract semantic meaning** - Transform text into embeddings for search, classification, and similarity tasks\n",
    "- **Understand context deeply** - Process and analyze complex documents and long-form content\n",
    "- **Work in multiple languages** - Use models optimized for English, German, French, and Spanish\n",
    "- **Build production systems** - Access enterprise-grade models with guaranteed uptime and support\n",
    "\n",
    "Think of Pharia Inference as your AI assistant API - always ready to understand, generate, and transform language for your applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé• Video Spotlight\n",
    "\n",
    "> **üìå TODO: EMBED PRODUCT SPOTLIGHT VIDEO HERE**\n",
    "> \n",
    "> *This section will contain a 2-3 minute video introducing Pharia Inference, its key capabilities, and value propositions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Architecture Overview\n",
    "\n",
    "> **üìå TODO: ADD ARCHITECTURE DIAGRAM HERE**\n",
    "> \n",
    "> *This section will contain a visual diagram showing:*\n",
    "> - *How your application connects to Pharia Inference API*\n",
    "> - *The relationship between SDKs and API endpoints*\n",
    "> - *Available models and their purposes*\n",
    "> - *Key components of the inference service*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Developers Use Pharia Inference\n",
    "\n",
    "Pharia Inference provides a REST API with endpoints for text generation, embeddings, chat, and more. To make integration simple, we provide Python SDKs that wrap these API endpoints:\n",
    "\n",
    "### Primary SDK: pharia-inference-sdk\n",
    "\n",
    "<pre style=\"line-height: 1.5;\">\n",
    "<b>Your Application</b>\n",
    "    ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ <b>pharia-inference-sdk (Python)</b>\n",
    "            ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ <span style=\"color: #999; font-size: 0.9em;\">Pharia Inference API\n",
    "                ‚îú‚îÄ‚îÄ /complete (Text generation)\n",
    "                ‚îú‚îÄ‚îÄ /embed (Semantic embeddings)  \n",
    "                ‚îú‚îÄ‚îÄ /chat (Conversational AI)\n",
    "                ‚îî‚îÄ‚îÄ /tokenize (Text processing)</span>\n",
    "</pre>\n",
    "\n",
    "The **pharia-inference-sdk** is our recommended approach. It provides:\n",
    "- Type-safe interfaces\n",
    "- Built-in error handling\n",
    "- Automatic authentication\n",
    "- Simplified request/response handling\n",
    "\n",
    "*Note: There's also an alternative SDK called `aleph-alpha-client` that provides similar functionality with a different interface style.*\n",
    "\n",
    "### Available Models:\n",
    "\n",
    "- **Pharia-1-LLM-7B-control**: Our flagship model for instruction following\n",
    "- **Pharia-1-LLM-7B-control-aligned**: Enhanced with safety alignments\n",
    "- **Pharia-1-Embedding models**: Specialized for semantic search (256, 768, or 4608 dimensions)\n",
    "- **Open-source models**: Various community models including Llama, Mistral, and others (when deployed in your infrastructure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Capabilities\n",
    "\n",
    "Here's what you can do with Pharia Inference APIs:\n",
    "\n",
    "#### Text Generation\n",
    "Generate human-like text for any purpose - from creative writing to technical documentation.\n",
    "\n",
    "**Example use**: \"Write a product description for...\" ‚Üí Polished, engaging content\n",
    "\n",
    "#### Chat Completions  \n",
    "Build conversational AI with context-aware responses.\n",
    "\n",
    "**Example use**: Customer support chatbots that understand context and provide helpful answers\n",
    "\n",
    "#### Semantic Embeddings\n",
    "Convert text into numerical representations that capture meaning.\n",
    "\n",
    "**Example use**: Find similar documents, classify content, or build recommendation systems\n",
    "\n",
    "#### Attention Manipulation (AtMan)\n",
    "Unique to Aleph Alpha - guide the model's focus for more controlled outputs by amplifying or suppressing attention to specific text segments.\n",
    "\n",
    "**Example use**: Emphasize certain parts of a document when summarizing, or suppress irrelevant sections\n",
    "\n",
    "*Note: This feature uses TextControl objects in the SDK. See the hands-on tutorials for implementation details.*\n",
    "\n",
    "#### Tokenization\n",
    "Understand how text is processed by the model.\n",
    "\n",
    "**Example use**: Calculate costs, manage context windows, prepare inputs\n",
    "\n",
    "#### Tool Calling\n",
    "Let models interact with external tools and APIs.\n",
    "\n",
    "**Example use**: Build AI agents that can search databases or perform calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Use Cases\n",
    "\n",
    "Developers are using Pharia Inference to power:\n",
    "\n",
    "### üìù Content Generation\n",
    "- Marketing copy and product descriptions\n",
    "- Technical documentation\n",
    "- Email drafts and responses\n",
    "- Creative writing assistance\n",
    "\n",
    "### ü§ñ Intelligent Assistants\n",
    "- Customer support chatbots\n",
    "- Internal knowledge base Q&A\n",
    "- Code explanation and generation\n",
    "- Personal productivity tools\n",
    "\n",
    "### üîç Semantic Search & Analysis\n",
    "- Document similarity matching\n",
    "- Content classification\n",
    "- Sentiment analysis\n",
    "- Information extraction\n",
    "\n",
    "### üåê Multilingual Applications\n",
    "- Cross-language search\n",
    "- Localized content generation\n",
    "- Translation assistance\n",
    "- Global customer support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Choose Pharia Inference?\n",
    "\n",
    "### üá™üá∫ European AI Leadership\n",
    "- **Data Sovereignty** - Complete control over your data, models, and deployment\n",
    "- **GDPR-Compliant by Design** - Built to meet EU data privacy regulations\n",
    "- **No Training on Your Data** - Your inputs remain private and secure\n",
    "- **Transparent AI Practices** - Explainable AI with attention manipulation capabilities\n",
    "\n",
    "### üè¢ Enterprise-Ready Infrastructure\n",
    "- **Production-Grade Reliability** - Built for mission-critical applications\n",
    "- **On-Premise Deployment** - Run models in your own data center with full control\n",
    "- **Flexible Deployment Options** - Choose cloud, on-premise, or hybrid configurations\n",
    "- **SLA Guarantees** - Enterprise support with defined service levels\n",
    "- **Scalable Architecture** - Handle millions of requests with consistent performance\n",
    "\n",
    "### üè† Complete Deployment Freedom\n",
    "- **True On-Premise Option** - Deploy entirely within your infrastructure, no external dependencies\n",
    "- **Air-Gapped Environments** - Support for completely isolated, high-security deployments\n",
    "- **Your Hardware, Your Rules** - Run on your GPUs with full performance optimization\n",
    "- **Hybrid Flexibility** - Mix on-premise sensitive workloads with cloud scalability\n",
    "- **No Vendor Lock-In** - Switch between deployment modes as your needs evolve\n",
    "\n",
    "### üí∞ Cost-Efficient at Scale\n",
    "- **Shared Inference** - Multiple instances can securely share GPU resources\n",
    "- **Dynamic Model Management** - Deploy and manage models without infrastructure overhead\n",
    "- **Pay-Per-Use Pricing** - Only pay for what you use, no idle resource costs\n",
    "- **Open-Source Model Support** - Run community models alongside commercial ones\n",
    "\n",
    "### üéØ Unique Technical Features\n",
    "- **Attention Manipulation (AtMan)** - Guide model focus for controlled, explainable outputs\n",
    "- **User-Defined Steering** - Customize model behavior without retraining\n",
    "- **Multilingual Excellence** - Models optimized for German, French, Spanish, and English\n",
    "- **Flexible Embeddings** - Choose from 256, 768, or 4608 dimensions for your use case\n",
    "\n",
    "### üîí Security & Compliance First\n",
    "- **Secure by Design** - Isolated instances with individual IAM controls\n",
    "- **Regulatory Compliance** - Adheres to EU copyright and data privacy laws\n",
    "- **Audit Trails** - Complete logging and monitoring capabilities\n",
    "- **Future-Proof Architecture** - Open interfaces prevent vendor lock-in\n",
    "\n",
    "### üöÄ Developer Experience\n",
    "- **One-Click Model Deployment** - Install and manage models through intuitive UI\n",
    "- **Comprehensive SDKs** - Type-safe Python clients with full documentation\n",
    "- **Unified API Interface** - Consistent experience across all models\n",
    "- **Token Efficiency** - Steering concepts save context space and reduce costs\n",
    "\n",
    "### üéõÔ∏è Advanced Capabilities\n",
    "- **Transcription API** - Process audio files up to 200MB with sentence-level timestamps\n",
    "- **Asynchronous Processing** - Queue-based system for handling heavy workloads\n",
    "- **Authentication-Based Reporting** - Track usage and performance by user/department\n",
    "- **Seamless PhariaAI Integration** - Works perfectly with Studio and OS components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Ready to start building with Pharia Inference? \n",
    "\n",
    "In the **Single Product Tutorials** section, you'll find hands-on guides for:\n",
    "- **Your First LLM Interaction** - Make your first API call in minutes\n",
    "- **Exploring Models** - Compare different models and their capabilities\n",
    "- **Building with Embeddings** - Create semantic search applications\n",
    "- **Advanced Techniques** - Master attention manipulation and tool calling\n",
    "\n",
    "---\n",
    "\n",
    "Continue your journey with Pharia Inference in our hands-on tutorials, where you'll build real AI applications from scratch!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
