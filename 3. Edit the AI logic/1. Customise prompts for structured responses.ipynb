{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Edit and test the AI Logic\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note:</b> this tutorial is run entirely on this Jupyter Notebook.\n",
    "</div>\n",
    "\n",
    "In this tutorial we understand how to edit the AI logic and test the changes using DevCSI.\n",
    "\n",
    "## Preconditions\n",
    "You have already done `2. Create & Run Applications` and have access to the boilerplate folder where the UI, Service and Skills are.\n",
    "\n",
    "Navigate to the `<your-application-folder>/skills/qa.py` to find a code that is similar to the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_skill import ChatParams, Csi, IndexPath, Message, skill\n",
    "from pydantic import BaseModel\n",
    "\n",
    "NAMESPACE = \"Studio\"\n",
    "COLLECTION = \"papers\"\n",
    "INDEX = \"asym-64\"\n",
    "\n",
    "\n",
    "class Input(BaseModel):\n",
    "    question: str\n",
    "    namespace: str = NAMESPACE\n",
    "    collection: str = COLLECTION\n",
    "    index: str = INDEX\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    answer: str | None\n",
    "\n",
    "\n",
    "#@skill\n",
    "def custom_rag(csi: Csi, input: Input) -> Output:\n",
    "    index = IndexPath(\n",
    "        namespace=input.namespace,\n",
    "        collection=input.collection,\n",
    "        index=input.index,\n",
    "    )\n",
    "\n",
    "    if not (documents := csi.search(index, input.question, 3, 0.5)):\n",
    "        return Output(answer=None)\n",
    "\n",
    "    context = \"\\n\".join([d.content for d in documents])\n",
    "    content = f\"\"\"Using the provided context documents below, answer the following question accurately and comprehensively. If the information is directly available in the context documents, cite it clearly. If not, use your knowledge to fill in the gaps while ensuring that the response is consistent with the given information. Do not fabricate facts or make assumptions beyond what the context or your knowledge base provides. Ensure that the response is structured, concise, and tailored to the specific question being asked.\n",
    "\n",
    "Input: {context}\n",
    "\n",
    "Question: {input.question}\n",
    "\"\"\"\n",
    "    message = Message.user(content)\n",
    "    params = ChatParams(max_tokens=512)\n",
    "    response = csi.chat(\"llama-3.1-8b-instruct\", [message], params)\n",
    "    return Output(answer=response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simple but effective change by improving the prompt and giving as output not only the response but also the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    answer: str | None\n",
    "    sources: list[str] | None\n",
    "\n",
    "#@skill\n",
    "def custom_rag(csi: Csi, input: Input) -> Output:\n",
    "    index = IndexPath(\n",
    "        namespace=input.namespace,\n",
    "        collection=input.collection,\n",
    "        index=input.index,\n",
    "    )\n",
    "\n",
    "    if not (documents := csi.search(index, input.question, 3, 0.5)):\n",
    "        return Output(answer=None)\n",
    "\n",
    "    context = \"\\n\".join([d.content for d in documents])\n",
    "    content = f\"\"\"Using the provided context documents below, answer the following question.\n",
    "Format your response with the following sections: \n",
    "1. SUMMARY: A brief 1-2 sentence answer to the question \n",
    "2. DETAILS: A comprehensive explanation with specific information from the context \n",
    "3. SOURCES: References to the specific parts of the context you used, if applicable If the information is not available in the context documents, clearly state this and provide a general response based on your knowledge, marked as [GENERAL KNOWLEDGE].\n",
    "\n",
    "Input: {context}\n",
    "\n",
    "Question: {input.question}\"\"\"\n",
    "\n",
    "    message = Message.user(content)\n",
    "    params = ChatParams(max_tokens=512)\n",
    "    response = csi.chat(\"llama-3.1-8b-instruct\", [message], params)\n",
    "    sources = [d.document_path.name for d in documents]\n",
    "    return Output(answer=response.message.content, sources=sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the new skill code to check if the result is improved by using the DevCSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pharia_skill.testing import DevCsi\n",
    "\n",
    "test_input = Input(question=\"What is an encoder?\")\n",
    "\n",
    "csi = DevCsi()\n",
    "custom_rag(csi, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with different variations of the prompt and different output types until you find the one that is more suitable for your application. You can also try with different input questions.\n",
    "\n",
    "Let's move now to the skill publishing and deployment \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-filippo",
   "language": "python",
   "name": "test-filippo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
